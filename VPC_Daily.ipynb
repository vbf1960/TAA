{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e592b7",
   "metadata": {},
   "source": [
    "## Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c7b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "import pybroker as pyb\n",
    "from pybroker import ExecContext, Strategy, StrategyConfig, YFinance, StrategyConfig\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from numba import njit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd49ceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<diskcache.core.Cache at 0x1bd7bab2220>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = StrategyConfig(max_long_positions=5)\n",
    "pyb.param('target_size', 1 / config.max_long_positions)\n",
    "pyb.param('rank_threshold', 6)\n",
    "pyb.enable_data_source_cache('yfinance')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fd6da",
   "metadata": {},
   "source": [
    "## Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf83bd2-a70d-4dd5-8ddc-5e27d86927b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "\n",
    "def ew13612_fnc(data):\n",
    "    roc12=ta.ROC(data.adj_close, timeperiod=12)\n",
    "    roc6=ta.ROC(data.adj_close, timeperiod=6)\n",
    "    roc3=ta.ROC(data.adj_close, timeperiod=3)\n",
    "    roc1=ta.ROC(data.adj_close, timeperiod=1)\n",
    "    \n",
    "    return (roc12 + roc6 + roc3 + roc1)/4\n",
    "\n",
    "ew13612_idx = pyb.indicator('ew13612_idx', lambda data: ew13612_fnc(data))\n",
    "\n",
    "def adj_close_fnc(data):\n",
    "    v_adj_close=data.adj_close\n",
    "    \n",
    "    return v_adj_close\n",
    "\n",
    "adj_close_idx = pyb.indicator('adj_close_idx', lambda data: adj_close_fnc(data))\n",
    "\n",
    "\n",
    "def pctl_chnl_fnc(data, lookback):\n",
    "\n",
    "    # @njit  # Enable Numba JIT.\n",
    "    def vec_pctl_chnl_fnc(data):\n",
    "        rolling_close = data.rolling(lookback)\n",
    "        pctl25 = rolling_close.quantile(0.25)\n",
    "        pctl75 = rolling_close.quantile(0.75)\n",
    "        closing_price = data.adj_close\n",
    "\n",
    "        result = np.where(closing_price < pctl25, -1, np.where(closing_price > pctl75, 1, 0))\n",
    "        return result\n",
    "    return vec_pctl_chnl_fnc(data)\n",
    "        \n",
    "pc252_idx = pyb.indicator('pc252_idx', pctl_chnl_fnc, lookback=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbface27",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42388238",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "pctChannelPosition <- function(prices,\n",
    "                               dayLookback = 60,\n",
    "                               lowerPct = .25, upperPct = .75) {\n",
    "  # Create a matrix of leading NAs to ensure proper alignment\n",
    "  leadingNAs <- matrix(nrow = dayLookback - 1, ncol = ncol(prices), NA)\n",
    "\n",
    "  # Calculate upper channel values\n",
    "  upperChannels <- runquantile(prices, k = dayLookback, probs = upperPct, endrule = \"trim\")\n",
    "  upperQ <- xts(rbind(leadingNAs, upperChannels), order.by = index(prices))\n",
    "\n",
    "  # Calculate lower channel values\n",
    "  lowerChannels <- runquantile(prices, k = dayLookback, probs = lowerPct, endrule = \"trim\")\n",
    "  lowerQ <- xts(rbind(leadingNAs, lowerChannels), order.by = index(prices))\n",
    "\n",
    "  # Initialize a matrix for positions\n",
    "   positions <- xts(matrix(nrow = nrow(prices), ncol = ncol(prices), NA), order.by = index(prices))\n",
    "\n",
    "  # Set positions based on the channel crossover conditions\n",
    "  positions[prices > upperQ & lag(prices) < upperQ] <- 1    # Cross up\n",
    "  positions[prices < lowerQ & lag(prices) > lowerQ] <- -1   # Cross down\n",
    "\n",
    "  # Fill missing values using last observation carried forward (na.locf)\n",
    "  positions <- na.locf(positions)\n",
    "\n",
    "  # Set remaining NA positions to 0\n",
    "  positions[is.na(positions)] <- 0\n",
    "\n",
    "  # Set column names of positions to match price data columns\n",
    "  colnames(positions) <- colnames(prices)\n",
    "\n",
    "  return(positions)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a70e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached bar data.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_apply_blockwise',\n",
       " '_apply_pairwise',\n",
       " '_apply_series',\n",
       " '_apply_tablewise',\n",
       " '_attributes',\n",
       " '_check_window_bounds',\n",
       " '_create_data',\n",
       " '_dir_additions',\n",
       " '_generate_cython_apply_func',\n",
       " '_get_window_indexer',\n",
       " '_gotitem',\n",
       " '_index_array',\n",
       " '_insert_on_column',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_protocol',\n",
       " '_make_numeric_only',\n",
       " '_numba_apply',\n",
       " '_obj_with_exclusions',\n",
       " '_on',\n",
       " '_prep_values',\n",
       " '_raise_monotonic_error',\n",
       " '_resolve_output',\n",
       " '_selected_obj',\n",
       " '_selection',\n",
       " '_selection_list',\n",
       " '_slice_axis_for_step',\n",
       " '_validate',\n",
       " '_validate_datetimelike_monotonic',\n",
       " '_validate_numeric_only',\n",
       " '_win_freq_i8',\n",
       " '_win_type',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'apply',\n",
       " 'axis',\n",
       " 'center',\n",
       " 'closed',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'exclusions',\n",
       " 'is_datetimelike',\n",
       " 'kurt',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'method',\n",
       " 'min',\n",
       " 'min_periods',\n",
       " 'ndim',\n",
       " 'obj',\n",
       " 'on',\n",
       " 'quantile',\n",
       " 'rank',\n",
       " 'sem',\n",
       " 'skew',\n",
       " 'std',\n",
       " 'step',\n",
       " 'sum',\n",
       " 'validate',\n",
       " 'var',\n",
       " 'win_type',\n",
       " 'window']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yfinance = YFinance()\n",
    "symbols=['SPY','PDBC','LQD','VNQ']\n",
    "df = yfinance.query(symbols, start_date='1/1/2015', end_date='8/1/2023')\n",
    "\n",
    "rolling_close = df['adj_close'].rolling(20)\n",
    "\n",
    "dir(rolling_close)\n",
    "\n",
    "# Group the DataFrame by the 'group' column\n",
    "# grouped = df.rolling(20'group')\n",
    "# dir(grouped)\n",
    "# # Output data with space between groups\n",
    "# for name, group in grouped:\n",
    "#     print(f\"Group {name}:\")\n",
    "#     print(group)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b19b88-5ee7-44c9-824c-bf785c659622",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "md = pd.read_csv('D:/Documents/Development/Jupyter/pybroker/market_dates.csv', parse_dates=['trade_dt'], index_col='trade_dt')\n",
    "# md.sort_values(by=['trade_dt'])[-20:]\n",
    "\n",
    "yfinance = YFinance()\n",
    "\n",
    "# symbols=['SPY','QQQ','IWM','VGK','EWJ','EEM','VNQ','PDBC','GLD','HYG','LQD','TLT']\n",
    "symbols=['SPY','PDBC','LQD','VNQ']\n",
    "\n",
    "df = yfinance.query(symbols, start_date='1/1/2015', end_date='8/1/2023')\n",
    "\n",
    "# df.rename(columns={\"date\":\"trade_dt\"}, inplace=True)\n",
    "# df.set_index('trade_dt', inplace=True)\n",
    "#[['Symbol']=='EEM']\n",
    "dom_df = pd.merge(df, md[['month_last_day']], left_on='date', right_on='trade_dt')\n",
    "eom_df = dom_df[dom_df['month_last_day'] == 'Y'][['date','symbol','adj_close']]\n",
    "eom_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5bce1d",
   "metadata": {},
   "source": [
    "## Percentile Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ad77a-20c6-4ef6-810a-cf9d8d5ee720",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_score = eom_df.copy()\n",
    "for lookback in [3,6,9,12]:\n",
    "    rolling_close = pc_score['adj_close'].rolling(lookback)\n",
    "    pctl25 = rolling_close.quantile(0.25)\n",
    "    pctl75 = rolling_close.quantile(0.75)\n",
    "    close_price = pc_score['adj_close']\n",
    "\n",
    "    # result = pd.Series(-1, index=close_price.index)\n",
    "    result = pd.Series(-1, index=close_price.index)\n",
    "    last_result=-1\n",
    "    for idx, value in close_price.items():\n",
    "        if close_price[idx] > pctl75[idx]:\n",
    "            result[idx]=1\n",
    "            last_result=1\n",
    "        elif (close_price[idx] > pctl25[idx]) & (last_result==1):\n",
    "            result[idx]=1\n",
    "            last_result=1\n",
    "        \n",
    "        pc_column = f\"pc_{lookback}\"\n",
    "        pc_score[pc_column] = result\n",
    "\n",
    "pc_score.set_index('date', inplace=True)\n",
    "pc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66cc86",
   "metadata": {},
   "source": [
    "## Channel Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97288092-b469-4732-85c8-85632b03e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_chan_score = pc_score.copy()\n",
    "def sum_pc(row):\n",
    "    pc_columns = ['pc_3', 'pc_6', 'pc_9', 'pc_12']\n",
    "    return row[list(pc_columns)].sum()/4\n",
    "\n",
    "pc_chan_score['pc_chan_score'] = pc_chan_score.apply(sum_pc, axis=1)\n",
    "pc_chan_score['pc_chan_score_abs'] = pc_chan_score.apply(sum_pc, axis=1).abs()\n",
    "pc_chan_score[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30d13d",
   "metadata": {},
   "source": [
    "## Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1d987-e64f-42eb-ac23-673dcb1c4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_vol = df[['date','symbol','adj_close']].copy() # yfinance.query(symbols, start_date='1/1/2015', end_date='8/1/2023')\n",
    "# pc_vol=pc_vol[['date','symbol','adj_close']].copy()\n",
    "\n",
    "pc_vol['date'] = pd.to_datetime(pc_vol['date'])\n",
    "\n",
    "# Sort the DataFrame by 'symbol' and 'date' to ensure proper order for rolling calculation\n",
    "pc_vol.sort_values(by=['symbol', 'date'], inplace=True)\n",
    "\n",
    "# Set 'date' as the index for the DataFrame\n",
    "pc_vol.set_index('date', inplace=True)\n",
    "\n",
    "# Calculate the rolling 20-day volatility for each symbol\n",
    "pc_vol['vol20'] = pc_vol.groupby('symbol')['adj_close'].transform(lambda x: x.rolling(window=20).std())\n",
    "# pc_vol['vol20_abs'] = pc_vol.groupby('symbol')['adj_close'].transform(lambda x: x.rolling(window=20).std()).abs()\n",
    "\n",
    "# pc_vol[-60:].sort_values(by=['date','symbol'])\n",
    "# pc_vol.groupby('symbol').size()/252\n",
    "pc_vol.sort_values(by=['date', 'adj_close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f0c89",
   "metadata": {},
   "source": [
    "##  Channel Score Plus Volatility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_vol.reset_index(inplace=True)\n",
    "\n",
    "# Merge based on 'date' and 'symbol'\n",
    "pc_chan_score_vol = pd.merge(\n",
    "    pc_chan_score,\n",
    "    pc_vol[['date','symbol','vol20']],\n",
    "    on=['date', 'symbol'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "pc_chan_score_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65200ff7",
   "metadata": {},
   "source": [
    "## Volatility Adjusted Channel Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_vol.reset_index(inplace=True)\n",
    "\n",
    "# Merge based on 'date' and 'symbol'\n",
    "pc_chan_score_vol = pd.merge(\n",
    "    pc_chan_score,\n",
    "    pc_vol[['date','symbol','vol20']],\n",
    "    on=['date', 'symbol'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "pc_vol_adj_score=pc_chan_score_vol.copy()\n",
    "pc_vol_adj_score['chan_score_inv_vol'] = pc_chan_score_vol['pc_chan_score'] * (1 / pc_chan_score_vol['vol20'])\n",
    "pc_vol_adj_score['chan_score_inv_vol_abs'] = pc_vol_adj_score['chan_score_inv_vol'].abs()\n",
    "pc_vol_adj_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b079d7b9",
   "metadata": {},
   "source": [
    "## Weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1024fb-9ab1-4a20-adf6-a62bd183d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_adj_date_sum = pc_vol_adj_score.groupby('date')['chan_score_inv_vol_abs'].sum()\n",
    "pc_score_vol_adj_dt_wght = pc_vol_adj_score.copy()\n",
    "\n",
    "for date, value in vol_adj_date_sum.items():\n",
    "    pc_score_vol_adj_dt_wght.loc[pc_score_vol_adj_dt_wght['date'] == date, 'vol_adj_sum_date'] = value\n",
    "\n",
    "pc_score_vol_adj_dt_wght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e74867-0b37-4bac-ab31-efe152dcb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pc_pct_alloc=pc_score_vol_adj_dt_wght.copy()\n",
    "# pc_pct_alloc['pct_alloc'] = pc_pct_alloc['pc_score_vol_adj'] / pc_pct_alloc['score_vol_adj_date_wght']\n",
    "pc_pct_alloc['pct_alloc'] = (pc_pct_alloc['chan_score_inv_vol_abs'] / pc_pct_alloc['vol_adj_sum_date']).apply(lambda x: '{:.2f}%'.format(x * 100))\n",
    "\n",
    "\n",
    "pc_pct_alloc[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc45e28",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
